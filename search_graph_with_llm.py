#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åœ–è­œæœç´¢å·¥å…·
åŠŸèƒ½ï¼š
1. è®€å– graph_analysis_data.json
2. æä¾›äº¤äº’å¼å‘½ä»¤è¡Œæœç´¢ç•Œé¢
3. é¡¯ç¤ºå¯¦é«”è©³ç´°ä¿¡æ¯åŠå…¶é—œä¿‚ç¶²çµ¡
"""

import json
import networkx as nx
import os
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from dotenv import load_dotenv
import re

# è¼‰å…¥ .env æª”æ¡ˆ
load_dotenv()

# è¨­å®š DeepSeek API
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "")
DEEPSEEK_BASE_URL = "https://api.deepseek.com"

llm = None
if DEEPSEEK_API_KEY:
    llm = ChatOpenAI(
        model="deepseek-chat",
        openai_api_key=DEEPSEEK_API_KEY,
        openai_api_base=DEEPSEEK_BASE_URL,
        temperature=0.1
    )
else:
    print("âš ï¸ Warning: DEEPSEEK_API_KEY not found. LLM features will be disabled.")

class GraphSearcher:
    def __init__(self, json_file="graph_analysis_data.json"):
        self.json_file = json_file
        self.G = None
        self.load_graph()

    def load_graph(self):
        """å¾ JSON æ–‡ä»¶åŠ è¼‰åœ–è­œ"""
        if not os.path.exists(self.json_file):
            print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°æ•¸æ“šæ–‡ä»¶ {self.json_file}")
            print("è«‹å…ˆé‹è¡Œ visualize_ms.py ç”Ÿæˆæ•¸æ“šæ–‡ä»¶ã€‚")
            return False

        try:
            print(f"ğŸ“‚ æ­£åœ¨åŠ è¼‰åœ–è­œæ•¸æ“š: {self.json_file} ...")
            with open(self.json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # é‡å»º NetworkX åœ–
            self.G = nx.node_link_graph(data)
            print(f"âœ… åœ–è­œåŠ è¼‰æˆåŠŸ!")
            print(f"   - ç¯€é»æ•¸: {self.G.number_of_nodes()}")
            print(f"   - é‚Šæ•¸: {self.G.number_of_edges()}")
            return True
        except Exception as e:
            print(f"âŒ åŠ è¼‰å¤±æ•—: {e}")
            return False

    def search(self, query, entity_type=None):
        """æœç´¢ç¯€é»ä¸¦é¡¯ç¤ºç›¸é—œä¿¡æ¯"""
        if not self.G:
            return False

        query = query.strip()
        if not query:
            return False

        print(f"\nğŸ” æœç´¢çµæœ: '{query}' (é¡å‹: {entity_type})")
        print("=" * 50)

        matches_name = []
        matches_type = []

        # éæ­·æ‰€æœ‰ç¯€é»
        for node, attrs in self.G.nodes(data=True):
            node_name = str(node)
            node_group = str(attrs.get('group', ''))

            # 1. åç¨±åŒ¹é…
            if query.lower() in node_name.lower():
                # ä¿®æ­£: å…ˆæ‰¾åˆ°åç¨±, ç„¶å¾Œåªä¿ç•™ç›¸é—œtype
                if entity_type and entity_type != "Unknown":
                    if entity_type.lower() in node_group.lower() or node_group.lower() in entity_type.lower():
                        matches_name.append(node)
                else:
                    matches_name.append(node)

            # 2. é¡å‹åŒ¹é… (æª¢æŸ¥ query æ˜¯å¦ç‚ºé¡å‹)
            # æƒ…æ³ A: ç”¨æˆ¶æœ "é›¶é£Ÿ"ï¼Œåœ–ä¸­æœ‰ group="é›¶é£Ÿ" çš„ç¯€é»
            if query.lower() in node_group.lower():
                if node not in matches_name and node not in matches_type:
                    matches_type.append(node)

        if not matches_name and not matches_type:
            print(f"âŒ æœªæ‰¾åˆ°åŒ¹é…çš„å¯¦é«”: {query}")
            return False

        # é¡¯ç¤ºåç¨±åŒ¹é…çµæœ
        if matches_name:
            print(f"âœ… æ‰¾åˆ° {len(matches_name)} å€‹åç¨±åŒ¹é…å¯¦é«”:\n")
            for node_name in matches_name:
                self._print_node_details(node_name)

        # é¡¯ç¤ºé¡å‹åŒ¹é…çµæœ
        if matches_type:
            print(f"ğŸ·ï¸ æ‰¾åˆ° {len(matches_type)} å€‹é¡å‹ç›¸é—œå¯¦é«” (åŒ¹é… '{query}' æˆ– '{entity_type}'):\n")
            # å¦‚æœæ•¸é‡å¤ªå¤šï¼Œåªé¡¯ç¤ºå‰ 5 å€‹è©³ç´°ä¿¡æ¯ï¼Œå…¶ä»–çš„åªåˆ—å‡ºåå­—
            for i, node_name in enumerate(matches_type):
                if i < 3: # åªè©³ç´°é¡¯ç¤ºå‰ 3 å€‹
                    self._print_node_details(node_name)
                else:
                    print(f"   â€¢ {node_name} (é¡å‹: {self.G.nodes[node_name].get('group')})")

            if len(matches_type) > 3:
                print(f"\n   ... (å…± {len(matches_type)} å€‹ï¼Œåƒ…é¡¯ç¤ºå‰ 3 å€‹è©³ç´°ä¿¡æ¯)")

        return True

    def _print_node_details(self, node_name):
        """æ‰“å°å–®å€‹ç¯€é»çš„è©³ç´°ä¿¡æ¯å’Œé—œä¿‚"""
        attrs = self.G.nodes[node_name]
        current_community = attrs.get('community')

        print(f"ğŸ“ å¯¦é«”: {node_name}")
        print(f"   é¡å‹: {attrs.get('group', 'æœªçŸ¥')}")

        # é¡¯ç¤ºç¤¾å€ä¿¡æ¯
        if current_community is not None:
            print(f"   ç¤¾å€: #{current_community}")

        # é¡¯ç¤ºæè¿°
        desc = attrs.get('description', '').replace('\n', '\n         ')
        if desc:
            print(f"   æè¿°: {desc}")

        print("-" * 30)

        # --- æ–°å¢: é¡¯ç¤ºåŒç¤¾å€å…§çš„å¼·é—œè¯å¯¦é«” ---
        if current_community is not None:
            # 1. æ‰¾å‡ºåŒç¤¾å€çš„æ‰€æœ‰æˆå“¡
            community_members = []
            for node in self.G.nodes():
                if self.G.nodes[node].get('community') == current_community:
                    community_members.append(node)

            print(f"   ğŸ˜ï¸  æ‰€å±¬ç¤¾å€: #{current_community} (å…± {len(community_members)} å€‹æˆå“¡)")

            # 2. æ‰¾å‡ºèˆ‡ç•¶å‰ç¯€é»æœ‰ç›´æ¥é€£æ¥çš„åŒç¤¾å€æˆå“¡ (æ ¸å¿ƒé—œè¯)
            community_neighbors = []

            # æ”¶é›†æ‰€æœ‰é„°å±… (ä¸åˆ†å‡ºå…¥)
            all_neighbors = set(self.G.successors(node_name)) | set(self.G.predecessors(node_name))

            for neighbor in all_neighbors:
                neighbor_attrs = self.G.nodes[neighbor]
                if neighbor_attrs.get('community') == current_community:
                    # ç²å–é‚Šçš„æ¬Šé‡ (å–æœ€å¤§å€¼å¦‚æœæœ‰å¤šæ¢é‚Š)
                    weight = 0
                    # æª¢æŸ¥å‡ºé‚Š
                    if self.G.has_edge(node_name, neighbor):
                        weight = max(weight, self.G[node_name][neighbor].get('weight', 1))
                    # æª¢æŸ¥å…¥é‚Š
                    if self.G.has_edge(neighbor, node_name):
                        weight = max(weight, self.G[neighbor][node_name].get('weight', 1))

                    community_neighbors.append((neighbor, weight))

            # æŒ‰æ¬Šé‡æ’åº
            community_neighbors.sort(key=lambda x: x[1], reverse=True)

            if community_neighbors:
                print(f"      ğŸ”¥ ç¤¾å€å…§çš„æ ¸å¿ƒé—œè¯ (Top 5):")
                for neighbor, weight in community_neighbors[:5]:
                    print(f"         â˜… {neighbor} (å¼·åº¦: {weight})")

            # 3. åˆ—å‡ºç¤¾å€å…§çš„å…¶ä»–é‡è¦æˆå“¡ (æŒ‰åº¦æ•¸æ’åºï¼Œå±•ç¤ºç¤¾å€å…¨è²Œ)
            # è¨ˆç®—ç¤¾å€å…§æ¯å€‹ç¯€é»çš„åº¦æ•¸
            member_degrees = []
            for member in community_members:
                if member == node_name: continue # è·³éè‡ªå·±
                degree = self.G.degree(member)
                member_degrees.append((member, degree))

            member_degrees.sort(key=lambda x: x[1], reverse=True)

            print(f"      ğŸ‘€ ç¤¾å€å…§çš„å…¶ä»–é‡è¦æˆå“¡:")
            shown_count = 0
            for member, degree in member_degrees:
                # é¿å…é‡è¤‡é¡¯ç¤ºå·²ç¶“åœ¨æ ¸å¿ƒé—œè¯è£¡é¡¯ç¤ºéçš„
                if member in [n for n, w in community_neighbors[:5]]:
                    continue
                print(f"         â€¢ {member}")
                shown_count += 1
                if shown_count >= 5: # æœ€å¤šé¡¯ç¤º5å€‹
                    break

            print("-" * 30)
        # å‡ºåº¦ (ä¸»å‹•é—œä¿‚)
        out_edges = list(self.G.out_edges(node_name, data=True))
        if out_edges:
            print("   â¡ï¸  ä¸»å‹•é—œä¿‚ (Out):")
            for _, target, edge_attrs in out_edges:
                rel_desc = edge_attrs.get('description', edge_attrs.get('label', 'ç›¸é—œ'))
                # ç°¡åŒ–æè¿°é¡¯ç¤º
                rel_desc = rel_desc.split('\n')[0] if rel_desc else "ç›¸é—œ"
                weight = edge_attrs.get('weight', 1)
                print(f"      -> {target} : {rel_desc} (å¼·åº¦: {weight})")

        # å…¥åº¦ (è¢«å‹•é—œä¿‚)
        in_edges = list(self.G.in_edges(node_name, data=True))
        if in_edges:
            print("   â¬…ï¸  è¢«å‹•é—œä¿‚ (In):")
            for source, _, edge_attrs in in_edges:
                rel_desc = edge_attrs.get('description', edge_attrs.get('label', 'ç›¸é—œ'))
                rel_desc = rel_desc.split('\n')[0] if rel_desc else "ç›¸é—œ"
                weight = edge_attrs.get('weight', 1)
                print(f"      <- {source} : {rel_desc} (å¼·åº¦: {weight})")

        print("=" * 50 + "\n")

def analyze_query_with_llm(query):
    """ä½¿ç”¨ LLM åˆ†æç”¨æˆ¶æŸ¥è©¢ï¼Œæå–é—œéµè©"""
    if not llm:
        return [{"entity_name": query, "entity_type": "Unknown"}]

    system_prompt = """ä½ æ˜¯ä¸€å€‹çŸ¥è­˜åœ–è­œæœç´¢åŠ©æ‰‹ã€‚ä½ çš„ä»»å‹™æ˜¯åˆ†æç”¨æˆ¶çš„è‡ªç„¶èªè¨€å•é¡Œï¼Œæå–å‡ºå¯èƒ½å­˜åœ¨æ–¼åœ–è­œä¸­çš„é—œéµå¯¦é«”åç¨±åŠå…¶é¡å‹ã€‚

    è«‹è¼¸å‡ºä¸€å€‹ JSON å°è±¡ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
    {
        "entities": [
            {
                "entity_name": "å¯¦é«”åç¨±",
                "entity_type": "å¯¦é«”é¡å‹ (å¦‚: äººç‰©, åœ°é», äº‹ä»¶, ç‰©å“, çµ„ç¹”, æ¦‚å¿µç­‰)"
            }
        ]
    }

    è¦å‰‡ï¼š
    1. æå–å•é¡Œä¸­çš„æ ¸å¿ƒå¯¦é«”ã€‚
    2. æ¨æ–·å¯¦é«”çš„é¡å‹ã€‚
    3. åªè¿”å› JSONï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡æœ¬ã€‚
    """

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=query)
    ]

    try:
        response = llm.invoke(messages)
        content = response.content.strip()

        # å˜—è©¦è§£æ JSON
        match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', content, re.DOTALL)
        if match:
            content = match.group(1)
        elif '{' in content:
             # ç°¡å–®çš„æå–
             start = content.find('{')
             end = content.rfind('}') + 1
             content = content[start:end]

        data = json.loads(content)
        return data.get("entities", [{"entity_name": query, "entity_type": "Unknown"}])
    except Exception as e:
        print(f"âš ï¸ LLM åˆ†æå¤±æ•—ï¼Œå°‡ä½¿ç”¨åŸå§‹æŸ¥è©¢: {e}")
        return [{"entity_name": query, "entity_type": "Unknown"}]

def main():
    searcher = GraphSearcher()

    if not searcher.G:
        return

    print("\nğŸ’¡ æç¤º: è¼¸å…¥å¯¦é«”åç¨±æˆ–è‡ªç„¶èªè¨€å•é¡Œé€²è¡Œæœç´¢")
    print("ğŸ‘‰ è¼¸å…¥ 'q' æˆ– 'exit' é€€å‡ºç¨‹åºã€‚\n")

    while True:
        try:
            user_input = input("Search (è¼¸å…¥å•é¡Œæˆ–å¯¦é«”) > ")
            if user_input.lower() in ['q', 'exit', 'quit']:
                print("ğŸ‘‹ å†è¦‹!")
                break

            # ä½¿ç”¨ LLM åˆ†æ
            print("ğŸ¤– æ­£åœ¨åˆ†æå•é¡Œ...")
            entities = analyze_query_with_llm(user_input)
            print(f"ğŸ” æå–å¯¦é«”: {json.dumps(entities, ensure_ascii=False)}")

            found_count = 0
            for entity in entities:
                name = entity.get('entity_name')
                etype = entity.get('entity_type')
                print(f"\n--- æœç´¢: {name} ({etype}) ---")
                if searcher.search(name, etype):
                    found_count += 1

            if found_count == 0:
                print("âŒ æ‰€æœ‰é—œéµè©å‡æœªæ‰¾åˆ°åŒ¹é…å¯¦é«”ã€‚")

        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è¦‹!")
            break
        except Exception as e:
            print(f"ç™¼ç”ŸéŒ¯èª¤: {e}")

if __name__ == "__main__":
    main()
